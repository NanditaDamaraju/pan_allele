{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from pan_allele_data_helpers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "log_transformed_ic50_cutoff = 1 - np.log(500)/np.log(5000)\n",
    "from keras.models import Graph\n",
    "import theano.tensor as T\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Activation, RepeatVector, Dropout, Reshape, Flatten, Merge, Permute\n",
    "import theano\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_allele_name(allele_name):\n",
    "    allele_name = allele_name.upper()\n",
    "    # old school HLA-C serotypes look like \"Cw\"\n",
    "    allele_name = allele_name.replace(\"CW\", \"C\")\n",
    "    patterns = [\n",
    "        \"HLA-\",\n",
    "        \"-\",\n",
    "        \"*\",\n",
    "        \":\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        allele_name = allele_name.replace(pattern, \"\")\n",
    "    return allele_name\n",
    "allele_groups, df = load_binding_data('files/bdata.2009.mhci.public.1.txt')\n",
    "allele_sequence_data, max_allele_length = load_allele_sequence_data('files/trimmed-human-class1.fasta')\n",
    "allele_list = sorted(create_allele_list(allele_groups, allele_sequence_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_list = sorted(create_allele_list(allele_groups, allele_sequence_data))\n",
    "allele = 'A0101'\n",
    "training_list.remove(allele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train', (87680, 9), (87680, 181), (87680,))\n",
      "('test', (3169, 9))\n",
      "[[ 0  0  0  8  0  0  0  0 18]]\n",
      "[[ 8 14  8 11  6 11  6  2 18]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "peptide_train, mhc_train, Y_train = get_model_data(training_list,\n",
    "                                                            allele_sequence_data,\n",
    "                                                            allele_groups,\n",
    "                                                            dense_mhc_model=None,\n",
    "                                                            peptide_length = 9,\n",
    "                                                            mhc_length=181,\n",
    "                                                            mhc_dense = None\n",
    "                                                            )\n",
    "peptide_test, mhc_test, Y_test = get_model_data([allele],\n",
    "                                                        allele_sequence_data,\n",
    "                                                        allele_groups,\n",
    "                                                        dense_mhc_model=None,\n",
    "                                                        peptide_length = 9,\n",
    "                                                        mhc_length=181,\n",
    "                                                        mhc_dense=None)\n",
    "peptide_train = np.matrix(peptide_train, dtype=int)\n",
    "print(\"train\",peptide_train.shape, mhc_train.shape, Y_train.shape)\n",
    "print(\"test\", peptide_test.shape)\n",
    "np.random.seed(1)\n",
    "print peptide_train[1]\n",
    "arr = np.arange(len(peptide_train))\n",
    "np.random.shuffle(arr)\n",
    "peptide_train = peptide_train[arr]\n",
    "print peptide_train[1], \n",
    "##[[ 8 14  8 11  6 11  6  2 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 peptide_embedding_size\n",
      "1 mhc_embedding_size\n",
      "2 peptide_hidden_size\n",
      "3 mhc_hidden_size\n",
      "4 combined_hidden_size\n",
      "5 combined_hidden_final\n",
      "{'combined_hidden_final': 64, 'peptide_embedding_size': 128, 'peptide_hidden_size': 128, 'mhc_embedding_size': 64, 'mhc_hidden_size': 128, 'combined_hidden_size': 128} {'dropout_peptide': 0.2, 'dropout_mhc': 0.2, 'dropout_merged': 0.2}\n",
      "Building Graph Model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer='rmsprop'\n",
    "peptide_length = 9\n",
    "maxlen_mhc = 181\n",
    "mhc_activation = 'tanh'\n",
    "peptide_activation = 'tanh'\n",
    "\n",
    "hyperparameters = {'sizes':[128,64,128,128,128,64],'dropouts':[0.2,0.2,0.2], 'mult_size':[16,16]}\n",
    "size_names = [\n",
    "        'peptide_embedding_size',\n",
    "        'mhc_embedding_size',\n",
    "        'peptide_hidden_size',\n",
    "        'mhc_hidden_size',\n",
    "        'combined_hidden_size',\n",
    "        'combined_hidden_final'\n",
    "        ]\n",
    "\n",
    "dropout_names = [\n",
    "        'dropout_merged',\n",
    "        'dropout_peptide',\n",
    "        'dropout_mhc'\n",
    "        ]\n",
    "mult_size = {\n",
    "        'mhc_m':hyperparameters['mult_size'][0],\n",
    "        'mhc_n':hyperparameters['mult_size'][1]\n",
    "}\n",
    "\n",
    "size_dict = {}\n",
    "dropout_dict = {}\n",
    "\n",
    "for idx, name in enumerate(size_names):\n",
    "    print idx,name\n",
    "    size_dict[name] = hyperparameters['sizes'][idx]\n",
    "\n",
    "for idx, name in enumerate(dropout_names):\n",
    "    dropout_dict[name] = hyperparameters['dropouts'][idx]\n",
    "\n",
    "\n",
    "print size_dict, dropout_dict\n",
    "\n",
    "print(\"Building Graph Model\")\n",
    "graph = Graph()\n",
    "\n",
    "graph.add_input(name='peptide', ndim=2)\n",
    "\n",
    "graph.add_input(name='mhc', ndim=2)\n",
    "\n",
    "graph.inputs['peptide'].input = T.imatrix()\n",
    "graph.inputs['mhc'].input = T.imatrix()\n",
    "\n",
    "##PEPTIDE\n",
    "\n",
    "graph.add_node(\n",
    "            Embedding(20,size_dict['peptide_embedding_size']),\n",
    "            name='peptide_embedding',\n",
    "            input='peptide')\n",
    "\n",
    "graph.add_node(\n",
    "            Flatten(),\n",
    "            name = 'peptide_flatten',\n",
    "            input = 'peptide_embedding')\n",
    "\n",
    "graph.add_node(\n",
    "                Dense(size_dict['peptide_embedding_size'] * peptide_length, mult_size['mhc_m'],\n",
    "                activation = peptide_activation ),\n",
    "            name='peptide_dense',\n",
    "            input='peptide_flatten'   )\n",
    "\n",
    "\n",
    "dropout_output_peptide = 'peptide_dense'\n",
    "if(dropout_dict['dropout_peptide']):\n",
    "    dropout_output_peptide = 'peptide_dropout'\n",
    "    graph.add_node(Dropout(dropout_dict['dropout_peptide']), name = 'peptide_dropout', input='peptide_dense')\n",
    "\n",
    "\n",
    "\n",
    "##MHC\n",
    "\n",
    "graph.add_node(\n",
    "            Embedding(20,size_dict['mhc_embedding_size']),\n",
    "            name='mhc_embedding',\n",
    "            input='mhc')\n",
    "\n",
    "graph.add_node(\n",
    "        Flatten(),\n",
    "        name = 'mhc_flatten',\n",
    "        input = 'mhc_embedding')\n",
    "\n",
    "graph.add_node(\n",
    "        Dense(size_dict['mhc_embedding_size'] * maxlen_mhc, size_dict['mhc_hidden_size'],\n",
    "            activation = mhc_activation),\n",
    "        name='mhc_dense',\n",
    "        input='mhc_flatten')\n",
    "\n",
    "dropout_output_mhc = 'mhc_dense'\n",
    "if(dropout_dict['dropout_mhc']):\n",
    "    dropout_output_mhc = 'mhc_dropout'\n",
    "    graph.add_node(Dropout(dropout_dict['dropout_mhc']), name = dropout_output_mhc, input='mhc_dense')\n",
    "\n",
    "graph.add_node(Dense(size_dict['mhc_hidden_size'], mult_size['mhc_m'] * mult_size['mhc_n'], activation = mhc_activation),\n",
    "                name = 'mhc_dense_2', input = dropout_output_mhc)\n",
    "graph.add_node(Reshape(mult_size['mhc_m'],mult_size['mhc_n']), name = 'mhc_final', input = 'mhc_dense_2')\n",
    "##MERGE\n",
    "\n",
    "graph.add_node(\n",
    "        Dense(mult_size['mhc_n'], size_dict['combined_hidden_size'],\n",
    "            activation = \"relu\"),\n",
    "        name='dense_merged_1',\n",
    "        inputs=[dropout_output_peptide,'mhc_final'],\n",
    "        merge_mode='matmul')\n",
    "\n",
    "\n",
    "graph.add_node(\n",
    "        Dropout(dropout_dict['dropout_merged']),\n",
    "        name = 'dense_dropout_1',\n",
    "        input='dense_merged_1')\n",
    "\n",
    "\n",
    "graph.add_node(\n",
    "        Dense(size_dict['combined_hidden_size'],size_dict['combined_hidden_final'],activation = \"relu\"),\n",
    "        name = 'dense_merged_2',\n",
    "        input = 'dense_dropout_1')\n",
    "\n",
    "\n",
    "graph.add_node(\n",
    "        Dropout(dropout_dict['dropout_merged']),\n",
    "        name = 'dense_dropout_2',\n",
    "        input='dense_merged_2')\n",
    "\n",
    "\n",
    "graph.add_node(\n",
    "        Dense(size_dict['combined_hidden_final'],1,activation = \"sigmoid\"),\n",
    "        name = 'dense_output',\n",
    "        input = 'dense_dropout_2')\n",
    "\n",
    "graph.add_output(\n",
    "        name='output',\n",
    "        input='dense_output')\n",
    "\n",
    "graph.compile(optimizer,{'output':'mse'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87680, 9)\n",
      "(<class 'numpy.matrixlib.defmatrix.matrix'>, <type 'numpy.ndarray'>)\n",
      "(87680, 181)\n",
      "(87680,)\n",
      "Epoch 0\n",
      " 1824/87680 [..............................] - ETA: 153s - output: 0.1312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-509323a2a681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Keras-0.1.1-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_order\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         history = self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, callbacks=callbacks, \\\n\u001b[0;32m--> 586\u001b[0;31m             validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/Keras-0.1.1-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, validation_split, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(peptide_train.shape)\n",
    "print(type(peptide_train), type(Y_train))\n",
    "print(mhc_train.shape)\n",
    "print(Y_train.shape)\n",
    "graph.fit(\n",
    "            {'peptide':peptide_train,'mhc':mhc_train, 'output': Y_train},\n",
    "            batch_size=32,\n",
    "            nb_epoch=1,\n",
    "            verbose = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding            (10, 181)            (10, 181, 32)       \n",
      "Convolution1D        (10, 181, 32)        (10, 178, 64)       \n",
      "Permute              (10, 178, 64)        (10, 64, 178)       \n",
      "Error: 'MaxPooling1D' object has no attribute 'subsample_length'\n",
      "Permute              (10, 64, 89)         (10, 89, 64)        \n",
      "Convolution1D        (10, 89, 64)         (10, 86, 64)        \n",
      "Permute              (10, 86, 64)         (10, 64, 86)        \n",
      "Error: 'MaxPooling1D' object has no attribute 'subsample_length'\n",
      "Permute              (10, 64, 43)         (10, 43, 64)        \n",
      "Flatten              (10, 43, 64)         (10, 2752)          \n",
      "Dense                (10, 2752)           (10, 64)            \n",
      "Reshape              (10, 64)             (10, 8, 8)          \n",
      "Embedding            (10, 9)              (10, 9, 32)         \n",
      "Convolution1D        (10, 9, 32)          (10, 6, 64)         \n",
      "Flatten              (10, 6, 64)          (10, 384)           \n",
      "Dense                (10, 384)            (10, 8)             \n",
      "Dense                (10, 8)              (10, 32)            \n",
      "Dense                (10, 32)             (10, 1)             \n"
     ]
    }
   ],
   "source": [
    "model = graph\n",
    "input_shapes = {'peptide':(10,9),'mhc':(10,181)}\n",
    "input_dummy = [np.zeros(input_shapes[name], dtype=np.float32)\n",
    "                       for name in model.input_order]\n",
    "inputs = [model.inputs[name].input\n",
    "                  for name in model.input_order]\n",
    "for l in [graph.nodes[c['name']] for c in graph.node_config]:\n",
    "    shape_i = theano.function(inputs, l.get_input(train=False).shape,\n",
    "                                  on_unused_input='ignore', allow_input_downcast=True) \n",
    "    shape_o = theano.function(inputs, l.get_output(train=False).shape,\n",
    "                                  on_unused_input='ignore', allow_input_downcast=True)\n",
    "    try:\n",
    "        in_shape = tuple(shape_i(*input_dummy))\n",
    "        out_shape = tuple(shape_o(*input_dummy))\n",
    "        config = l.get_config()\n",
    "        print(\"%-20s %-20s %-20s\" % (config['name'],  in_shape, out_shape))\n",
    "    except Exception as e:\n",
    "        print(\"Error: %s\" % e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in [graph.nodes[c['name']] for c in graph.node_config]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxlen_mhc = 181 \n",
    "nb_epoch = 64\n",
    "optimizer='rmsprop'\n",
    "mhc_activation='relu' \n",
    "peptide_activation= 'relu'\n",
    "\n",
    "max_features = 20\n",
    "maxlen_peptide = 9\n",
    "batch_size = 32\n",
    "embedding_dims = 32\n",
    "nb_filters =  50\n",
    "filter_length = 4\n",
    "hidden_dims = 64\n",
    "\n",
    "graph = Graph()\n",
    "graph.add_input(name='peptide', ndim=2)\n",
    "graph.inputs['peptide'].input = T.imatrix()\n",
    "\n",
    "\n",
    "graph.add_node( Embedding(max_features, embedding_dims),\n",
    "                name = 'peptide_embedding',\n",
    "                input = 'peptide'\n",
    "                )\n",
    "graph.add_node( Convolution1D(\n",
    "                    input_dim=embedding_dims,\n",
    "                    nb_filter=nb_filters,\n",
    "                    filter_length=filter_length,\n",
    "                    border_mode=\"valid\",\n",
    "                    activation=\"relu\",\n",
    "                    subsample_length=1),\n",
    "\n",
    "                name = 'peptide_conv',\n",
    "                input = 'peptide_embedding'\n",
    "                )\n",
    "\n",
    "graph.add_node(Flatten(), name = 'peptide_flatten',input='peptide_embedding')\n",
    "graph.add_node(Dense(288,6), name= 'peptide_dense', input= 'peptide_flatten')\n",
    "##MERGE\n",
    "last_peptide = 'peptide_dense'\n",
    "last_mhc = 'peptide_conv'\n",
    "graph.add_node( Dense(50, 1),\n",
    "                name='merged_output',\n",
    "                inputs=[last_peptide,last_mhc,],\n",
    "                merge_mode='mul',\n",
    "                \n",
    "                )\n",
    "graph.add_output(   name='output',  input='merged_output')\n",
    "\n",
    "\n",
    "graph.compile(  optimizer,  {'output':'mse'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
