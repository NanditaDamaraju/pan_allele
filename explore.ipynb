{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from pan_allele_data_helpers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "log_transformed_ic50_cutoff = 1 - np.log(500)/np.log(5000)\n",
    "from keras.models import Graph\n",
    "import theano.tensor as T\n",
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Activation, RepeatVector, Dropout, Reshape, Flatten, Merge, Permute\n",
    "import numpy as np\n",
    "import theano\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "import collections\n",
    "import random\n",
    "from five_fold_validation import split_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get 10% of training set to select epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137655\n",
      "123888 13766 123888\n",
      "['human\\tHLA-B-0802\\t9\\tTBD\\tYHLGGIEGL\\t>\\t20000.0\\n'\n",
      " 'human\\tHLA-B-4501\\t10\\tTBD\\tVPLDEDFRKY\\t>\\t70000.0\\n'\n",
      " 'human\\tHLA-A-0201\\t9\\tTBD\\tCMLDGGNML\\t=\\t1041.666667\\n' ...,\n",
      " 'human\\tHLA-A-3002\\t9\\tTBD\\tAYLRKHFSM\\t>\\t75000.0\\n'\n",
      " 'macaque\\tMamu-A-11\\t9\\tTBD\\tAENLKVTVY\\t=\\t1065.861894\\n'\n",
      " 'human\\tHLA-A-1101\\t9\\tTBD\\tGSDGGLDDY\\t>\\t20000.0\\n']\n"
     ]
    }
   ],
   "source": [
    "from pan_allele_data_helpers import *\n",
    "\n",
    "path = \"/Users/NanditaD/Intern/mhclearn\"\n",
    "mhc_sequence_fasta_file=path+\"/py/pan_allele/files/pseudo/pseudo_sequences.fasta\"\n",
    "iedb_data_file= path + \"/py/pan_allele/files/bdata.2009.mhci.public.1.txt\"\n",
    "with open(iedb_data_file, \"rb\") as source:\n",
    "    lines = [line for line in source]\n",
    "print(len(lines))\n",
    "lines = np.array(lines[1:])\n",
    "arr = np.arange(len(lines))\n",
    "np.random.shuffle(arr)\n",
    "train, test = split_train_test(arr, 10, 2)\n",
    "print (len(train), len(test), len(lines[train]))\n",
    "print(lines[train])\n",
    "with open(path + \"/py/pan_allele/files/2009_test_10.txt\", \"wb\") as sink_test:\n",
    "    print (\"species\\tmhc\\tpeptide_length\\tcv\\tsequence\\tinequality\\tmeas\", file=sink_test)\n",
    "    sink_test.write(\"\".join(lines[test]))\n",
    "with open(path + \"/py/pan_allele/files/2009_train_10.txt\", \"wb\") as sink_train:\n",
    "    print (\"species\\tmhc\\tpeptide_length\\tcv\\tsequence\\tinequality\\tmeas\", file=sink_train)\n",
    "    sink_train.write(\"\".join(lines[train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9047\n",
      "81916\n"
     ]
    }
   ],
   "source": [
    "allele_groups_test, df_test = load_binding_data(\"files/2009_test_10.txt\")\n",
    "allele_sequence_data, max_allele_length = load_allele_sequence_data(mhc_sequence_fasta_file)\n",
    "alleles_test = create_allele_list(allele_groups_test, allele_sequence_data)\n",
    "print (len(df_test))\n",
    "allele_groups_train, df_train = load_binding_data('files/2009_train_10.txt')\n",
    "alleles_train = create_allele_list(allele_groups_train, allele_sequence_data)\n",
    "print (len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get 2013 data - 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalize_allele_name(allele_name):\n",
    "    allele_name = allele_name.upper()\n",
    "    # old school HLA-C serotypes look like \"Cw\"\n",
    "    allele_name = allele_name.replace(\"CW\", \"C\")\n",
    "    patterns = [\n",
    "        \"HLA-\",\n",
    "        \"-\",\n",
    "        \"*\",\n",
    "        \":\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        allele_name = allele_name.replace(pattern, \"\")\n",
    "    return allele_name\n",
    "allele_groups_2013, df_2013 = load_binding_data('files/bdata.2013.mhci.public.1.txt')\n",
    "allele_sequence_data, max_allele_length = load_allele_sequence_data('files/trimmed-human-class1.fasta')\n",
    "allele_list_2013 = sorted(create_allele_list(allele_groups_2013, allele_sequence_data))\n",
    "pep_dict  = collections.defaultdict(dict)\n",
    "for allele in allele_list_2013:\n",
    "    #print allele, np.sum(allele_groups_2013[allele][2] < 500),'\\t', (allele_groups_2013[allele][2] < 500).size\n",
    "    for idx, peptide in enumerate(allele_groups_2013[allele][1]):\n",
    "        pep_dict[allele][peptide] = allele_groups_2013[allele][2][idx]\n",
    "        \n",
    "    #if (allele_groups[allele][2]).size > 1000:\n",
    "        #print allele, np.sum(allele_groups[allele][2] < 500),'\\t', (allele_groups[allele][2] < 500).size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_groups_2009, df_2009 = load_binding_data('files/bdata.2009.mhci.public.1.txt')\n",
    "allele_list_2009 = sorted(create_allele_list(allele_groups_2009, allele_sequence_data))\n",
    "#for allele in allele_list:\n",
    "#    print allele, np.sum(allele_groups[allele][2] < 500),'\\t', (allele_groups[allele][2] < 500).size\n",
    "    #if (allele_groups[allele][2]).size > 1000:\n",
    "        #print allele, np.sum(allele_groups[allele][2] < 500),'\\t', (allele_groups[allele][2] < 500).size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"files/bdata2013-2009.txt\",'w')\n",
    "print (\"species\\tmhc\\tpeptide_length\\tcv\\tsequence\\tinequality\\tmeas\", file=f)\n",
    "for allele in allele_list_2013:\n",
    "    #print allele, len(allele_groups_2009[allele][2]),'\\t', len(allele_groups_2013[allele][2])\n",
    "    allele_groups_2013, df_2013 = load_binding_data('files/bdata.2013.mhci.public.1.txt')\n",
    "    peptides_2013 = allele_groups_2013[allele][1]\n",
    "    try:\n",
    "        allele_groups_2009, df_2009 = load_binding_data('files/bdata.2009.mhci.public.1.txt')\n",
    "        peptides_2009 = allele_groups_2009[allele][1]\n",
    "        intersection = list(set(peptides_2009).intersection(peptides_2013))\n",
    "        [peptides_2013.remove(peptide) for peptide in intersection]\n",
    "        for peptide in peptides_2013:\n",
    "            print (\"human\\t\"+allele+\"\\t9\\tTBD\\t\"+peptide+\"\\t=\\t\"+str(pep_dict[allele][peptide]),file=f) \n",
    "        #print peptides_2009, peptides_2013,allele_groups_2009[allele][1]\n",
    "        #print allele,'\\t', len(intersection),'\\t', len(peptides_2009),'\\t', len(peptides_2013)\n",
    "    except Exception as e: \n",
    "        for peptide in peptides_2013:\n",
    "            print (\"human\\t\"+allele+\"\\t9\\tTBD\\t\"+peptide+\"\\t=\\t\"+str(pep_dict[allele][peptide]),file=f) \n",
    "    \n",
    "#print allele_groups_2009['A0210'][1], allele_groups_2013['A0210'][1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Allele occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0101 391 \t 3169\n",
      "A0201 2198 \t 6961\n",
      "A0202 1073 \t 2314\n",
      "A0203 1278 \t 3937\n",
      "A0205 31 \t 36\n",
      "A0206 1267 \t 3223\n",
      "A0207 7 \t 30\n",
      "A0210 0 \t 18\n",
      "A0211 361 \t 1038\n",
      "A0212 275 \t 1143\n",
      "A0216 160 \t 894\n",
      "A0219 204 \t 1203\n",
      "A0250 88 \t 132\n",
      "A0301 958 \t 4601\n",
      "A0302 2 \t 2\n",
      "A11 31 \t 31\n",
      "A1101 1139 \t 3862\n",
      "A2 18 \t 30\n",
      "A2301 291 \t 1513\n",
      "A2402 322 \t 1985\n",
      "A2403 241 \t 1165\n",
      "A2501 66 \t 519\n",
      "A26 4 \t 4\n",
      "A2601 260 \t 2395\n",
      "A2602 67 \t 202\n",
      "A2603 25 \t 205\n",
      "A2902 470 \t 1839\n",
      "A3001 569 \t 1949\n",
      "A3002 235 \t 912\n",
      "A3101 681 \t 3309\n",
      "A3201 275 \t 575\n",
      "A3301 224 \t 1616\n",
      "A6601 4 \t 4\n",
      "A6801 641 \t 1700\n",
      "A6802 643 \t 3188\n",
      "A6901 222 \t 2079\n",
      "A8001 113 \t 782\n",
      "B0702 566 \t 2974\n",
      "B0801 458 \t 2084\n",
      "B0802 19 \t 486\n",
      "B0803 9 \t 217\n",
      "B1402 0 \t 3\n",
      "B1501 830 \t 3142\n",
      "B1502 124 \t 164\n",
      "B1503 332 \t 416\n",
      "B1509 16 \t 346\n",
      "B1517 271 \t 846\n",
      "B1801 186 \t 1661\n",
      "B2701 1 \t 1\n",
      "B2702 0 \t 4\n",
      "B2703 0 \t 433\n",
      "B2705 351 \t 2324\n",
      "B3501 505 \t 1993\n",
      "B3503 1 \t 5\n",
      "B3801 3 \t 136\n",
      "B3901 170 \t 879\n",
      "B4001 282 \t 2326\n",
      "B4002 164 \t 474\n",
      "B4201 2 \t 2\n",
      "B4402 105 \t 1295\n",
      "B4403 101 \t 502\n",
      "B4501 103 \t 483\n",
      "B4601 91 \t 1406\n",
      "B4801 68 \t 861\n",
      "B5101 171 \t 1336\n",
      "B5301 211 \t 620\n",
      "B5401 139 \t 621\n",
      "B5701 215 \t 1719\n",
      "B5801 394 \t 2444\n",
      "B5802 9 \t 31\n",
      "B7 42 \t 48\n",
      "B7301 14 \t 115\n",
      "E0101 0 \t 1\n"
     ]
    }
   ],
   "source": [
    "allele_groups, df = load_binding_data('files/bdata.2009.mhci.public.1.txt')\n",
    "for allele in sorted(allele_groups.keys()):\n",
    "    print (allele, np.sum(allele_groups[allele][2] < 500),'\\t', (allele_groups[allele][2] < 500).size)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_residues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-99501df2e3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msequence_array\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mallele_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_residues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/py/pan_allele/files/trimmed-human-class1-IEDB.fasta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rU'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fasta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_residues' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sequence_array =[]\n",
    "allele_list = []\n",
    "if(remove_residues):\n",
    "    with open(path + '/py/pan_allele/files/trimmed-human-class1-IEDB.fasta','rU') as f:\n",
    "        for record in SeqIO.parse(f, 'fasta'):\n",
    "            name, sequence = record.description, str(record.seq)\n",
    "            name = name.split(' ')[0]\n",
    "            sequence_array.append(sequence)\n",
    "            allele_list.append(name)\n",
    "\n",
    "\n",
    "\n",
    "    sequence_mat = np.array([list(seq) for seq in sequence_array])\n",
    "    delete_columns = []\n",
    "\n",
    "    for columns in range(0,sequence_mat.shape[1]):\n",
    "        char_occurence_dict =  Counter(sequence_mat[:,columns])\n",
    "        print char_occurence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
